# -*- coding: utf-8 -*-
"""
Actividad 3: Prototipo QA JurÃ­dico (RAG ligero)
- Base de conocimiento: archivos .txt en knowledge_base/
- Retrieval: SentenceTransformers + cosine similarity
- Reader QA: modelo en espaÃ±ol (transformers pipeline)
- Entrega: respuesta + fuente (doc/chunk) + evidencia en output/
"""

from __future__ import annotations

import os
from dataclasses import dataclass
from pathlib import Path
from typing import List, Tuple

import numpy as np
from sentence_transformers import SentenceTransformer
from transformers import pipeline


# -----------------------------
# ConfiguraciÃ³n
# -----------------------------
KB_DIR = Path("knowledge_base")
OUT_DIR = Path("output")
OUT_DIR.mkdir(parents=True, exist_ok=True)

# Embeddings (multilingÃ¼e, funciona bien para espaÃ±ol)
EMBED_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# Modelo QA en espaÃ±ol (si falla, puedes cambiar por otro)
QA_MODEL = "mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es"

TOP_K = 3
CHUNK_SIZE = 600      # caracteres por fragmento
CHUNK_OVERLAP = 80    # solapamiento entre fragmentos


# -----------------------------
# Estructuras
# -----------------------------
@dataclass
class Chunk:
    doc_name: str
    chunk_id: int
    text: str


# -----------------------------
# Utilidades
# -----------------------------
def ensure_sample_kb() -> None:
    """
    Si la carpeta knowledge_base/ estÃ¡ vacÃ­a, crea 6 textos base simulados
    (leyes/guÃ­as/resÃºmenes) para poder ejecutar y evidenciar.
    """
    KB_DIR.mkdir(parents=True, exist_ok=True)
    existing = list(KB_DIR.glob("*.txt"))
    if existing:
        return

    samples = {
        "01_acoso_laboral_guia.txt": (
            "GuÃ­a bÃ¡sica sobre acoso laboral (Colombia).\n\n"
            "El acoso laboral comprende conductas persistentes y demostrables ejercidas sobre un trabajador, "
            "encaminadas a infundir miedo, intimidaciÃ³n, terror o angustia, causar perjuicio laboral, generar "
            "desmotivaciÃ³n o inducir la renuncia.\n\n"
            "Medidas recomendadas: documentar hechos (fechas, testigos), reportar al Ã¡rea de talento humano, "
            "usar comitÃ©s de convivencia, y acudir a inspecciÃ³n del trabajo si persiste.\n"
        ),
        "02_violencia_intrafamiliar_resumen.txt": (
            "Resumen: violencia intrafamiliar.\n\n"
            "La violencia intrafamiliar puede incluir violencia fÃ­sica, psicolÃ³gica, econÃ³mica o patrimonial "
            "en el contexto familiar. Ante riesgo, se pueden solicitar medidas de protecciÃ³n.\n\n"
            "En contextos de atenciÃ³n a poblaciÃ³n vulnerable, es clave evitar revictimizaciÃ³n y garantizar "
            "enfoque diferencial.\n"
        ),
        "03_conciliacion_extrajudicial.txt": (
            "ConciliaciÃ³n extrajudicial.\n\n"
            "En algunos asuntos, la conciliaciÃ³n puede ser un requisito de procedibilidad. "
            "Se recomienda verificar si el caso admite conciliaciÃ³n y ante quÃ© autoridad.\n\n"
            "La conciliaciÃ³n busca soluciones acordadas y reduce congestiÃ³n judicial.\n"
        ),
        "04_derechos_migrantes_orientacion.txt": (
            "OrientaciÃ³n general para personas migrantes.\n\n"
            "Las personas migrantes pueden acceder a rutas de atenciÃ³n y orientaciÃ³n jurÃ­dica, "
            "en especial cuando enfrentan vulneraciones de derechos. Es importante identificar "
            "la entidad competente y el mecanismo idÃ³neo (tutela, denuncia, queja, etc.).\n"
        ),
        "05_derechos_victimas_conflicto.txt": (
            "Victimas del conflicto armado: orientaciÃ³n.\n\n"
            "Las vÃ­ctimas pueden tener derecho a medidas de asistencia, atenciÃ³n, reparaciÃ³n y garantÃ­as "
            "de no repeticiÃ³n. Se recomienda orientar sobre rutas institucionales y acompaÃ±amiento.\n"
        ),
        "06_derecho_familia_alimentos.txt": (
            "Derecho de familia: alimentos.\n\n"
            "Las obligaciones alimentarias buscan garantizar el sustento de menores o personas dependientes. "
            "Puede existir acuerdo o fijaciÃ³n por autoridad competente. Se deben considerar capacidad econÃ³mica "
            "y necesidades.\n"
        ),
    }

    for name, text in samples.items():
        (KB_DIR / name).write_text(text, encoding="utf-8")

    print(f"âœ… Base de conocimiento creada en: {KB_DIR.resolve()}")


def chunk_text(text: str, chunk_size: int, overlap: int) -> List[str]:
    text = " ".join(text.split())  # normaliza espacios
    chunks = []
    start = 0
    while start < len(text):
        end = min(len(text), start + chunk_size)
        chunks.append(text[start:end])
        if end == len(text):
            break
        start = max(0, end - overlap)
    return chunks


def cosine_sim_matrix(a: np.ndarray, b: np.ndarray) -> np.ndarray:
    # a: (n, d), b: (m, d)
    a_norm = a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)
    b_norm = b / (np.linalg.norm(b, axis=1, keepdims=True) + 1e-12)
    return np.dot(a_norm, b_norm.T)


def build_index(embedder: SentenceTransformer) -> Tuple[List[Chunk], np.ndarray]:
    chunks: List[Chunk] = []
    for doc_path in sorted(KB_DIR.glob("*.txt")):
        doc_text = doc_path.read_text(encoding="utf-8", errors="replace")
        parts = chunk_text(doc_text, CHUNK_SIZE, CHUNK_OVERLAP)
        for i, part in enumerate(parts, start=1):
            chunks.append(Chunk(doc_name=doc_path.name, chunk_id=i, text=part))

    if not chunks:
        raise RuntimeError("La base de conocimiento estÃ¡ vacÃ­a. Agrega archivos .txt en knowledge_base/.")

    chunk_texts = [c.text for c in chunks]
    embeddings = embedder.encode(chunk_texts, convert_to_numpy=True, show_progress_bar=False)
    return chunks, embeddings


def retrieve(question: str, chunks: List[Chunk], chunk_emb: np.ndarray, embedder: SentenceTransformer, top_k: int) -> List[Tuple[Chunk, float]]:
    q_emb = embedder.encode([question], convert_to_numpy=True, show_progress_bar=False)
    sims = cosine_sim_matrix(chunk_emb, q_emb).reshape(-1)  # (n,)
    top_idx = np.argsort(-sims)[:top_k]
    return [(chunks[i], float(sims[i])) for i in top_idx]


def answer_question(question: str, retrieved: List[Tuple[Chunk, float]], qa_pipe) -> dict:
    # Construye contexto uniendo los top chunks
    context = "\n\n".join([f"[{c.doc_name} :: chunk {c.chunk_id}] {c.text}" for c, _ in retrieved])

    result = qa_pipe(question=question, context=context)
    # result: {'score':..., 'start':..., 'end':..., 'answer':...}
    return {"answer": result.get("answer", ""), "score": float(result.get("score", 0.0)), "context": context}


def save_evidence(question: str, retrieved: List[Tuple[Chunk, float]], qa_result: dict) -> Path:
    out_path = OUT_DIR / "evidencia_actividad3_qa.txt"
    lines = []
    lines.append("Actividad 3 - Prototipo QA JurÃ­dico (RAG ligero)\n")
    lines.append("================================================\n\n")
    lines.append(f"Pregunta del usuario:\n{question}\n\n")
    lines.append(f"Respuesta:\n{qa_result['answer']}\n")
    lines.append(f"Confianza (score): {qa_result['score']:.4f}\n\n")
    lines.append("Fuentes recuperadas (top-k):\n")
    for chunk, sim in retrieved:
        preview = (chunk.text[:200] + "...") if len(chunk.text) > 200 else chunk.text
        lines.append(f"- {chunk.doc_name} | chunk {chunk.chunk_id} | similitud={sim:.4f}\n  {preview}\n")
    lines.append("\n")

    out_path.write_text("".join(lines), encoding="utf-8")
    return out_path


# -----------------------------
# Main
# -----------------------------
def main() -> None:
    ensure_sample_kb()

    print("ğŸ”§ Cargando modelos...")
    embedder = SentenceTransformer(EMBED_MODEL)

    # QA pipeline (CPU). Si tienes GPU, se puede configurar device=0.
    qa_pipe = pipeline("question-answering", model=QA_MODEL, tokenizer=QA_MODEL)

    print("ğŸ“š Indexando base de conocimiento...")
    chunks, chunk_emb = build_index(embedder)
    print(f"âœ… Documentos: {len(list(KB_DIR.glob('*.txt')))} | Fragmentos indexados: {len(chunks)}")

    # Pregunta interactiva
    question = input("\nEscribe tu pregunta jurÃ­dica: ").strip()
    if not question:
        print("âš ï¸ Pregunta vacÃ­a. Finalizando.")
        return

    retrieved = retrieve(question, chunks, chunk_emb, embedder, TOP_K)
    qa_result = answer_question(question, retrieved, qa_pipe)

    print("\n==============================")
    print("âœ… Respuesta del sistema")
    print("==============================")
    print(f"Pregunta: {question}")
    print(f"Respuesta: {qa_result['answer']}")
    print(f"Score: {qa_result['score']:.4f}\n")

    print("ğŸ“Œ Fuentes (top-k):")
    for c, sim in retrieved:
        print(f"- {c.doc_name} | chunk {c.chunk_id} | similitud={sim:.4f}")

    evidence_path = save_evidence(question, retrieved, qa_result)
    print(f"\nğŸ“„ Evidencia guardada en: {evidence_path.resolve()}")


if __name__ == "__main__":
    # Evita que transformers meta logs excesivos
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    main()